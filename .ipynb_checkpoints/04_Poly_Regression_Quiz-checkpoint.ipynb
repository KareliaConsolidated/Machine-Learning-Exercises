{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -3.35320000e-01  1.12439502e-01 -3.77032139e-02\n",
      "   1.26426417e-02 -4.23933061e-03]\n",
      " [ 1.00000000e+00  2.16000000e-02  4.66560000e-04  1.00776960e-05\n",
      "   2.17678234e-07  4.70184985e-09]\n",
      " [ 1.00000000e+00 -1.19438000e+00  1.42654358e+00 -1.70383513e+00\n",
      "   2.03502660e+00 -2.43059507e+00]\n",
      " [ 1.00000000e+00 -6.50460000e-01  4.23098212e-01 -2.75208463e-01\n",
      "   1.79012097e-01 -1.16440208e-01]\n",
      " [ 1.00000000e+00 -2.80010000e-01  7.84056001e-02 -2.19543521e-02\n",
      "   6.14743813e-03 -1.72134415e-03]\n",
      " [ 1.00000000e+00  1.93258000e+00  3.73486546e+00  7.21792628e+00\n",
      "   1.39492200e+01  2.69579835e+01]\n",
      " [ 1.00000000e+00  1.22620000e+00  1.50356644e+00  1.84367317e+00\n",
      "   2.26071204e+00  2.77208510e+00]\n",
      " [ 1.00000000e+00  7.47270000e-01  5.58412453e-01  4.17284874e-01\n",
      "   3.11824468e-01  2.33017070e-01]\n",
      " [ 1.00000000e+00  3.32853000e+00  1.10791120e+01  3.68771565e+01\n",
      "   1.22746722e+02  4.08566146e+02]\n",
      " [ 1.00000000e+00  2.87457000e+00  8.26315268e+00  2.37530108e+01\n",
      "   6.82796923e+01  1.96274755e+02]\n",
      " [ 1.00000000e+00 -1.48662000e+00  2.21003902e+00 -3.28548821e+00\n",
      "   4.88427249e+00 -7.26105717e+00]\n",
      " [ 1.00000000e+00  3.76290000e-01  1.41594164e-01  5.32804680e-02\n",
      "   2.00489073e-02  7.54420333e-03]\n",
      " [ 1.00000000e+00  1.43918000e+00  2.07123907e+00  2.98088585e+00\n",
      "   4.29003130e+00  6.17412724e+00]\n",
      " [ 1.00000000e+00  2.41830000e-01  5.84817489e-02  1.41426413e-02\n",
      "   3.42011495e-03  8.27086399e-04]\n",
      " [ 1.00000000e+00 -2.79140000e+00  7.79191396e+00 -2.17503486e+01\n",
      "   6.07139232e+01 -1.69476845e+02]\n",
      " [ 1.00000000e+00  1.08176000e+00  1.17020470e+00  1.26588063e+00\n",
      "   1.36937903e+00  1.48133946e+00]\n",
      " [ 1.00000000e+00  2.81555000e+00  7.92732180e+00  2.23197709e+01\n",
      "   6.28424310e+01  1.76936006e+02]\n",
      " [ 1.00000000e+00  5.49240000e-01  3.01664578e-01  1.65686253e-01\n",
      "   9.10015174e-02  4.99816734e-02]\n",
      " [ 1.00000000e+00  2.36449000e+00  5.59081296e+00  1.32194213e+01\n",
      "   3.12571896e+01  7.39073121e+01]\n",
      " [ 1.00000000e+00 -1.01925000e+00  1.03887056e+00 -1.05886882e+00\n",
      "   1.07925205e+00 -1.10002765e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Regression Exercise\n",
    "# Get some practice implementing polynomial regression in this exercise. In poly_data.csv, you can see data generated for one predictor feature ('Var_X') and one outcome feature ('Var_Y'), following a non-linear trend. Use sklearn's PolynomialFeatures class to extend the predictor feature column into multiple columns with polynomial features. Play around with different degrees of polynomial and the Test Run button to see what fits best: when you think you have the best-fitting degree, press the Submit button to check your work!\n",
    "\n",
    "# Perform the following steps below:\n",
    "\n",
    "# 1. Load in the data\n",
    "\n",
    "# The data is in the file called 'data.csv'. Note that this data has a header line.\n",
    "# Make sure that you've split out the data into the predictor feature in X and outcome feature in y.\n",
    "# For X, make sure it is in a 2-d array of 20 rows by 1 column. You might need to use NumPy's reshape function to accomplish this.\n",
    "\n",
    "# 2. Create polynomial features\n",
    "\n",
    "# Create an instance of sklearn's PolynomialFeatures class and assign it to the variable poly_feat. Pay attention to how to set the degree of features, since that will be how the exercise is evaluated.\n",
    "# Create the polynomial features by using the PolynomialFeatures object's .fit_transform() method. The \"fit\" side of the method considers how many features are needed in the output, and the \"transform\" side applies those considerations to the data provided to the method as an argument. Assign the new feature matrix to the X_poly variable.\n",
    "\n",
    "# 3. Build a polynomial regression model\n",
    "\n",
    "# Create a polynomial regression model by combining sklearn's LinearRegression class with the polynomial features. Assign the fit model to poly_model.\n",
    "\n",
    "# TODO: Add import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Assign the data to predictor and outcome variables\n",
    "# TODO: Load the data\n",
    "train_data = pd.read_csv('Datasets/LinearRegression/poly_data.csv')\n",
    "X = train_data['Var_X'].values.reshape(-1, 1)\n",
    "y = train_data['Var_Y'].values\n",
    "\n",
    "# Create polynomial features\n",
    "# TODO: Create a PolynomialFeatures object, then fit and transform the\n",
    "# predictor feature\n",
    "poly_feat = PolynomialFeatures(degree = 4)\n",
    "X_poly = poly_feat.fit_transform(X)\n",
    "\n",
    "# Make and fit the polynomial regression model\n",
    "# TODO: Create a LinearRegression object and fit it to the polynomial predictor\n",
    "# features\n",
    "poly_model = LinearRegression(fit_intercept = False).fit(X_poly, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
